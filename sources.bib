% Bibliography for PhysMDT research project
% Physics Masked Diffusion Transformer for Symbolic Equation Discovery

@inproceedings{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title     = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {30},
  year      = {2017},
  url       = {https://arxiv.org/abs/1706.03762}
}

@inproceedings{biggio2021neural,
  author    = {Biggio, Luca and Bendinelli, Tommaso and Neitz, Alexander and Lucchi, Aur{\'e}lien and Parascandolo, Giambattista},
  title     = {Neural Symbolic Regression that Scales},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {936--945},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06427}
}

@inproceedings{kamienny2022end,
  author    = {Kamienny, Pierre-Alexandre and d'Ascoli, St{\'e}phane and Lample, Guillaume and Charton, Fran{\c{c}}ois},
  title     = {End-to-End Symbolic Regression with Transformers},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {35},
  pages     = {10269--10281},
  year      = {2022},
  url       = {https://arxiv.org/abs/2204.10532}
}

@inproceedings{dascoli2022deep,
  author    = {d'Ascoli, St{\'e}phane and Kamienny, Pierre-Alexandre and Lample, Guillaume and Charton, Fran{\c{c}}ois},
  title     = {Deep Symbolic Regression for Recurrent Sequences},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.04600}
}

@article{udrescu2020ai,
  author    = {Udrescu, Silviu-Marian and Tegmark, Max},
  title     = {{AI Feynman}: A Physics-Inspired Method for Symbolic Regression},
  journal   = {Science Advances},
  volume    = {6},
  number    = {16},
  pages     = {eaay2631},
  year      = {2020},
  doi       = {10.1126/sciadv.aay2631},
  url       = {https://arxiv.org/abs/1905.11481}
}

@inproceedings{cranmer2020discovering,
  author    = {Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
  title     = {Discovering Symbolic Models from Deep Learning with Inductive Biases},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {33},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.11287}
}

@article{brunton2016sindy,
  author    = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
  title     = {Discovering Governing Equations from Data by Sparse Identification of Nonlinear Dynamical Systems},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {113},
  number    = {15},
  pages     = {3932--3937},
  year      = {2016},
  doi       = {10.1073/pnas.1517384113},
  url       = {https://arxiv.org/abs/1509.03580}
}

@inproceedings{sahoo2024mdlm,
  author    = {Sahoo, Subham Sekhar and Arriola, Marianne and Gokaslan, Aaron and Marroquin, Edgar Mariano and Rush, Alexander M. and Schiff, Yair and Chiu, Justin T. and Kuleshov, Volodymyr},
  title     = {Simple and Effective Masked Diffusion Language Models},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  url       = {https://arxiv.org/abs/2406.07524}
}

@article{nie2025llada,
  author    = {Nie, Shen and Zhu, Fengqi and You, Zebin and Zhang, Xiaolu and Ou, Jingyang and Hu, Jun and Zhou, Jun and Lin, Yankai and Wen, Ji-Rong and Li, Chongxuan},
  title     = {Large Language Diffusion Models},
  journal   = {arXiv preprint arXiv:2502.09992},
  year      = {2025},
  url       = {https://arxiv.org/abs/2502.09992}
}

@misc{architects2025arc,
  author    = {{The ARChitects (Lambda Labs)}},
  title     = {{ARC 2025 Solution by the ARChitects}: Masked Diffusion with Recursive Soft-Masking Refinement},
  year      = {2025},
  url       = {https://lambdalabsml.github.io/ARC2025_Solution_by_the_ARChitects/}
}

@article{greydanus2019hamiltonian,
  author    = {Greydanus, Sam and Dzamba, Misko and Yosinski, Jason},
  title     = {Hamiltonian Neural Networks},
  journal   = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {32},
  year      = {2019},
  url       = {https://arxiv.org/abs/1906.01563}
}

@article{cranmer2020lagrangian,
  author    = {Cranmer, Miles and Greydanus, Sam and Hoyer, Stephan and Battaglia, Peter and Spergel, David and Ho, Shirley},
  title     = {Lagrangian Neural Networks},
  journal   = {arXiv preprint arXiv:2003.04630},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.04630}
}

@article{valipour2021symbolicgpt,
  author    = {Valipour, Mojtaba and You, Bowen and Panju, Maysum and Ghodsi, Ali},
  title     = {{SymbolicGPT}: A Generative Transformer Model for Symbolic Regression},
  journal   = {arXiv preprint arXiv:2106.14131},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.14131}
}

@inproceedings{lee2019set,
  author    = {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  title     = {Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {3744--3753},
  year      = {2019},
  url       = {https://arxiv.org/abs/1810.00825}
}

@article{tenachi2023physo,
  author    = {Tenachi, Wassim and Ibata, Rodrigo and Diakogiannis, Foivos I.},
  title     = {Deep Symbolic Regression for Physics Guided by Units Constraints: Toward the Automated Discovery of Physical Laws},
  journal   = {The Astrophysical Journal},
  year      = {2023},
  url       = {https://arxiv.org/abs/2303.03192}
}

@inproceedings{landajuela2022unified,
  author    = {Landajuela, Mikel and Lee, Chak Shing and Yang, Jiachen and Glatt, Ruben and Santiago, Claudio P. and Aravena, Ignacio and Mundhenk, Terrell and Mulber, Garrett and Petersen, Brenden K.},
  title     = {A Unified Framework for Deep Symbolic Regression},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/dbca58f35bddc6e4003b2dd80e42f838-Paper-Conference.pdf}
}
