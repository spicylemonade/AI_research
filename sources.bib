% Bibliography for research project
% PhysMDT: Masked Diffusion Transformer for Physics Equation Derivation

@inproceedings{lample2020deep,
  title={Deep Learning for Symbolic Mathematics},
  author={Lample, Guillaume and Charton, Fran{\c{c}}ois},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://arxiv.org/abs/1912.01412}
}

@article{udrescu2020ai,
  title={{AI Feynman}: A physics-inspired method for symbolic regression},
  author={Udrescu, Silviu-Marian and Tegmark, Max},
  journal={Science Advances},
  volume={6},
  number={16},
  pages={eaay2631},
  year={2020},
  publisher={American Association for the Advancement of Science}
}

@article{udrescu2020ai2,
  title={{AI Feynman 2.0}: Pareto-optimal symbolic regression exploiting graph modularity},
  author={Udrescu, Silviu-Marian and Tan, Andrew and Feng, Jiaqi and Neto, Orisvaldo and Wu, Tailin and Tegmark, Max},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4860--4871},
  year={2020}
}

@misc{arc2025architects,
  title={{ARC 2025} Solution by the {ARChitects}: Masked Diffusion Models for {ARC-AGI}},
  author={{Lambda Labs ML Team}},
  year={2025},
  howpublished={\url{https://lambdalabsml.github.io/ARC2025_Solution_by_the_ARChitects/}},
  note={1st place solution for the ARC-AGI-2 competition}
}

@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}

@article{nie2025llada,
  title={Large Language Diffusion Models},
  author={Nie, Shen and Zhu, Fengqi and You, Chao and Zhang, Xiaojian and Ou, Jianfeng and Hu, Jun and Lu, Yanqin and Zhou, Zhiheng and Lin, Jie and Wen, Ji-Rong and Li, Chongxuan},
  journal={arXiv preprint arXiv:2502.09992},
  year={2025},
  note={LLaDA: Large Language Diffusion with mAsking}
}

@inproceedings{sahoo2024simple,
  title={Simple and Effective Masked Diffusion Language Models},
  author={Sahoo, Subham Sekhar and Arriola, Marianne and Schiff, Yair and Gokaslan, Aaron and Marroquin, Edgar and Chiu, Justin T and Rush, Alexander and Kuleshov, Volodymyr},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024},
  url={https://arxiv.org/abs/2406.07524},
  note={MDLM}
}

@inproceedings{biggio2021neural,
  title={Neural Symbolic Regression that Scales},
  author={Biggio, Luca and Bendinelli, Tommaso and Neitz, Alexander and Lucchi, Aurelien and Parascandolo, Giambattista},
  booktitle={International Conference on Machine Learning},
  year={2021},
  url={https://arxiv.org/abs/2106.06427},
  note={NeSymReS}
}

@article{lewkowycz2022solving,
  title={Solving Quantitative Reasoning Problems with Language Models},
  author={Lewkowycz, Aitor and Andreassen, Anders and Dohan, David and Dyer, Ethan and Michalewski, Henryk and Ramasesh, Vinay and Slone, Ambrose and Anil, Cem and Schlag, Imanol and Gutman-Solo, Theo and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3843--3857},
  year={2022},
  note={Minerva}
}

@inproceedings{azerbayev2024llemma,
  title={Llemma: An Open Language Model for Mathematics},
  author={Azerbayev, Zhangir and Schoelkopf, Hailey and Paster, Keiran and Santos, Marco Dos and McAleer, Stephen and Jiang, Albert Q and Deng, Jia and Biderman, Stella and Welleck, Sean},
  booktitle={International Conference on Learning Representations},
  year={2024},
  url={https://arxiv.org/abs/2310.10631}
}

@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{su2024roformer,
  title={{RoFormer}: Enhanced Transformer with Rotary Position Embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier},
  note={RoPE}
}

@article{cranmer2023interpretable,
  title={Interpretable Machine Learning for Science with {PySR} and {SymbolicRegression.jl}},
  author={Cranmer, Miles},
  journal={arXiv preprint arXiv:2305.01582},
  year={2023}
}

@inproceedings{kamienny2022end,
  title={End-to-end symbolic regression with transformers},
  author={Kamienny, Pierre-Alexandre and d'Ascoli, St{\'e}phane and Lample, Guillaume and Charton, Fran{\c{c}}ois},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{koza1994genetic,
  title={Genetic programming as a means for programming computers by natural selection},
  author={Koza, John R},
  journal={Statistics and Computing},
  volume={4},
  number={2},
  pages={87--112},
  year={1994},
  publisher={Springer},
  note={Foundation work for genetic programming / gplearn}
}

@inproceedings{sun2023tpsr,
  title={{TPSR}: Transformer-based Planning for Symbolic Regression},
  author={Sun, Wei and Magliacane, Sara},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023},
  url={https://github.com/deep-symbolic-mathematics/TPSR}
}

@article{lacava2021srbench,
  title={Contemporary Symbolic Regression Methods and their Relative Performance},
  author={La Cava, William and Orzechowski, Patryk and Burlacu, Bogdan and de Franca, Fabr{\'\i}cio and Virgolin, Marco and Jin, Ying and Kommenda, Michael and Moore, Jason},
  journal={arXiv preprint arXiv:2107.14351},
  year={2021},
  note={SRBench}
}

@misc{lacava2016strogatz,
  title={{ODE-Strogatz}: A benchmark set of 2-state nonlinear ordinary differential equations},
  author={La Cava, William},
  year={2016},
  howpublished={\url{https://github.com/lacava/ode-strogatz}}
}

@article{nguyen2011benchmark,
  title={Semantically-based crossover in genetic programming: Application to real-valued symbolic regression},
  author={Nguyen, Quang Uy and Nguyen, Xuan Hoai and O'Neill, Michael and McKay, Robert I and Galv{\'a}n-L{\'o}pez, Edgar},
  journal={Genetic Programming and Evolvable Machines},
  volume={12},
  number={2},
  pages={91--119},
  year={2011},
  publisher={Springer}
}

@inproceedings{dascoli2023odeformer,
  title={{ODEFormer}: Symbolic Regression of Dynamical Systems with Transformers},
  author={d'Ascoli, St{\'e}phane and Becker, S{\"o}ren and Schwaller, Philippe and Mathis, Alexander and Kilbertus, Niki},
  booktitle={International Conference on Learning Representations},
  year={2024},
  url={https://arxiv.org/abs/2310.05573}
}
