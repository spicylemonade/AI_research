# Autoregressive Baseline Training Configuration
model:
  d_model: 512
  n_heads: 8
  n_enc_layers: 4
  n_dec_layers: 6
  d_ff: 2048
  dropout: 0.1

training:
  n_samples: 20000
  n_epochs: 15
  batch_size: 32
  learning_rate: 0.0003
  weight_decay: 0.01
  scheduler: cosine_annealing
  seed: 42

data:
  max_n_points: 50
  max_vars: 10

evaluation:
  beam_width: 10
  max_seq_len: 128
